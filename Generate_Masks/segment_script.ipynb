{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d85dec7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script loads a pre-trained SAM model to generate and save binary segmentation masks for all .png images in a specified input directory, \n",
    "storing the results in an output directory. \n",
    "\n",
    "This script was run on CeRAI Labs compute cluster since my Laptop couldn't efficiently run the Segment-Anything-Model model.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator\n",
    "\n",
    "\n",
    "#### Directoery names and model path. Enter the absolute path ovr here to ensure it works properly.\n",
    "\n",
    "foreground_input_img_base_dir = \"/home/gokul/Hier-Legal-Graph/mimic_dataset/mimiciv_dataset/2.2/Tempp/Generate_Masks/foreground\"\n",
    "foreground_output_img_base_dir = \"/home/gokul/Hier-Legal-Graph/mimic_dataset/mimiciv_dataset/2.2/Tempp/Generate_Masks/foreground_mask\"\n",
    "sam_checkpoint_path = \"/home/gokul/Hier-Legal-Graph/mimic_dataset/mimiciv_dataset/2.2/Tempp/Generate_Masks/SAM_Checkpoint/sam_vit_l_0b3195.pth\"\n",
    "\n",
    "######\n",
    "\n",
    "os.makedirs(foreground_output_img_base_dir, exist_ok=True)\n",
    "\n",
    "# Get all .png files in the directory\n",
    "img_list = [f for f in os.listdir(foreground_input_img_base_dir) if f.endswith('.png')]\n",
    "img_list.sort()\n",
    "\n",
    "# Load SAM (ViT-L) with pretrained weights\n",
    "sam = sam_model_registry[\"vit_l\"](checkpoint=sam_checkpoint_path)\n",
    "sam.to(device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "mask_generator = SamAutomaticMaskGenerator(sam)\n",
    "\n",
    "def process_image(input_path: str, output_path: str):\n",
    "    image = cv2.imread(input_path)\n",
    "    if image.shape[:2] != (512, 512):\n",
    "        image = cv2.resize(image, (512, 512), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    # Generate all masks, pick the largest by area\n",
    "    masks = mask_generator.generate(image_rgb)\n",
    "    best_mask = max(masks, key=lambda m: m[\"area\"])\n",
    "    seg = best_mask[\"segmentation\"]  \n",
    "\n",
    "    mask_uint8 = (seg.astype(np.uint8)) * 255           \n",
    "    binary_output = np.ascontiguousarray(mask_uint8)    \n",
    "\n",
    "    contours, _ = cv2.findContours(binary_output, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cv2.drawContours(binary_output, contours, -1, color=255, thickness=cv2.FILLED)                                                   \n",
    "    cv2.imwrite(output_path, binary_output)\n",
    "\n",
    "\n",
    "for img_name in img_list:\n",
    "    input_path = os.path.join(foreground_input_img_base_dir, img_name)\n",
    "    output_path = os.path.join(foreground_output_img_base_dir, img_name)\n",
    "\n",
    "    process_image(input_path, output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Object-Stitch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
